## Updates to Splatter {#splatter-update}

I have continued to develop the Splatter package since publication, improving
the package infrastructure and implementing additional simulation models. This
section briefly describes changes to the software since the publication and
provides an up-to-date comparison of the current simulation models.

The most significant change to the infrastructure of Splatter is switching from
using the SCESet object provided by early versions of the scater package as the
output of simulation functions, to using the SingleCellExperiment object
[@Lun2017-jj]. This object has been available since mid-2017 and is intended to
be the core object for all Bioconductor packages working with scRNA-seq data.
It is based on Bioconductor's SummarizedExperiment object which consists of
feature by sample matrices linked to annotation data frames for both features
and samples. The SingleCellExperiment object adds features specifically useful
for scRNA-seq data, including slots for storing the results of dimensionality
reduction techniques and normalisation size factors, as well as conveniently
named accessors for information commonly used in analyses. In practical terms,
changing objects has not changed how Splatter is used but it does ensure that
the results of Splatter simulations are immediately compatible with tools in
the Bioconductor ecosystem. Display of the Splatter parameters objects has also
been improved, including colouring of output to highlight which parameters have
been changed from the default values.

Minor changes have also been made to the Splat simulation model. At the request
of users we have modified the parameters controlling additional dropout to
allow them to be specified by whole experiment (the previous method), sample
batch, cell group or individual cell. This allows users investigating the
effects of dropout to simulate datasets where different cell types or batches
are differently affected by the dropout phenomenon. Many of the other
parameters could already be specified at different levels, but extending this to
the dropout parameters provides extra flexibility to the Splat model. In the
original model the total number of reads in each cell was sampled from a
log-normal distribution, however some users have come across datasets where the
normal distribution was a better fit, which caused the Splat estimation
procedure to fail. We now allow either the log-normal or normal distributions
to be used for this part of the model and the estimation procedure attempts to
identify which is more appropriate for each input dataset.

Another model that has seen changes is that from the BASiCS package. The
authors of BASiCS have made significant improvements to how they estimate
parameters, particularly for datasets without internal spike-ins but where
multiple batches exist. BASiCS now uses non-linear regression to capture the
trend between gene mean and over-dispersion [@Eling2018-lp]. This method is now
used as part of the default estimation procedure for the BASiCS model within
Splatter, resulting in simulations that are a much better match for the
original dataset.

I have also added four new simulation models to Splatter, bringing the number of
models to 10. These new models are:

* mfa -- Simulation of a bifurcating pseudotime trajectory. This simulation can
  optionally include genes with changes in expression along the trajectory and
  added dropout [@Campbell2017-yh].
* PhenoPath -- Pseudotime trajectory including genes that show differential
  expression, changes along pseudotime, interaction effects or combinations of
  these [@Campbell2018-dz].
* ZINB-WaVE -- Sophisticated zero-inflated negative-binomial distribution based
  simulation that includes cell and gene-level covariates [@Risso2018-dg].
* SparseDC -- Simulates a set of clusters across two conditions, where
  some clusters may be present in only one condition [@Barron2017-nd].

More details about the models used by these packages are available in the
associated publications and package documentation.

### Performance of current simulations

\FloatBarrier

To demonstrate the performance of the current simulation models I have repeated
some of the analysis from the publication using the Tung dataset
[@Tung2017-ry]. Parameters for each of the models were estimated from a sample
of 500 cells from the Tung data and synthetic datasets were produced for each
model using these parameters. The time taken for the estimation and simulation
steps is shown in Appendix \@ref(sim-timings) and versions of the packages used
in Appendix \@ref(sim-packages). The comparison functions within Splatter were
then used to evaluate the differences between the simulated datasets and the
real data they were based on. Figure \@ref(fig:simulation-summary) summarises
this evaluation by showing the ranking of the median absolute deviation (MAD)
for each model across a range of metrics.

```{r simulation-summary, fig.cap = "(ref:cap-sim-summary)", fig.scap = "(ref:scap-sim-summary)", out.width = "100%"}
sim_summary <- read_tsv(here("data/simulation-summary.tsv"),
                        col_types = cols(
                            .default = col_double(),
                            Dataset = col_character(),
                            Statistic = col_character()
                        )) %>%
    mutate(Statistic = factor(
        Statistic,
        levels = rev(c("Mean", "Variance", "MeanVar", "LibSize", "ZerosCell",
                       "ZerosGene", "MeanZeros"))
    )) %>%
    mutate(Dataset = factor(
        Dataset,
        levels = c("Splat", "SplatDrop", "Simple", "BASiCS", "Lun", "Lun2",
                   "Lun2ZINB", "mfa", "PhenoPath", "scDD", "SparseDC",
                   "ZINBWaVE"),
        labels = c("Splat", "Splat (Drop)", "Simple", "BASiCS", "Lun", "Lun2",
                   "Lun2 (ZINB)", "mfa", "PhenoPath", "scDD", "SparseDC",
                   "ZINB-WaVE")
    )) %>%
    mutate(Rank = factor(MADRank))

p1 <- ggplot(sim_summary, aes(x = Dataset, y = Statistic, fill = Rank)) +
    geom_tile() +
    coord_equal() +
    scale_fill_viridis_d(direction = -1) +
    scale_y_discrete(labels = c("Mean"      = "Mean",
                                "Variance"  = "Variance",
                                "MeanVar"   = "Mean-Variance",
                                "LibSize"   = "Library Size",
                                "ZerosCell" = "% Zeros (Cell)",
                                "ZerosGene" = "% Zeros (Gene)",
                                "MeanZeros" = "Mean-Zeros")) +
    ggtitle("Rank of MAD from real data") +
    guides(fill = guide_legend(ncol = 1)) +
    theme_minimal() +
    theme(plot.title = element_text(size = 24, face = "bold", hjust = 0.4),
          axis.title = element_blank(),
          axis.text = element_text(size = 12),
          axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5),
          panel.grid = element_blank(),
          strip.text = element_text(size = 16, face = "bold"),
          legend.title = element_text(size = 14),
          legend.text = element_text(size = 12),
          legend.key.size = unit(25, "points"),
          legend.position = "right")

ggsave(here("figures/03-sim-summary.pdf"), p1, height = 6, width = 8)
ggsave(here("figures/03-sim-summary.png"), p1, height = 6, width = 8)

knitr::include_graphics(here::here("figures/03-sim-summary.png"))
```

(ref:scap-sim-summary) Performance of current Splatter simulations.

(ref:cap-sim-summary) Performance of current Splatter simulations. Synthetic datasets were produced using parameters estimated from 500 random cells from the Tung dataset. Plot shows the rank of median absolute deviation (MAD) from the real dataset on a variety of measures from least similar (blue) to most similar (yellow). The ZINB-WaVE model best reproduces this dataset, followed by the updated BASiCS model. The Splat model also performs well despite having a less sophisticated estimation procedure.

This comparison clearly shows that the ZINB-WaVE model produces the closest
match to this dataset. The similarity to the real dataset suggests that the
model used by ZINB-WaVE, and particularly the procedure used to estimate the
parameters in it, is effective for scRNA-seq data. ZINB-WaVE was originally
designed for dimensionality reduction but also has applications in
normalisation and differential expression testing [@Van_den_Berge2018-ip]. In
contrast to the previously published analysis, the BASiCS model is also a very
good match, with the improvement in performance coming from the new
regression-based estimation method. Unfortunately, the BASiCS normalisation
method relies on knowing predefined groups of cells, which limits its
usefulness for exploratory experiments. The Splat method does not match the
performance of ZINB-WaVE and BASiCS but still does a reasonable job of
reproducing this dataset, despite having a much simpler (and quicker)
estimation procedure. While producing realistic datasets is extremely
important, the real strength of the Splat model lies in its flexibility to
simulate many kinds of experiment and its reporting of intermediate values that
can be used to evaluate methods. As observed in the publication, we again see
that the zero-inflated versions of the Splat and Lun2 models perform worse than
the regular versions on this UMI dataset. However, this is in contrast to the
extremely good performance of ZINB-WaVE which also uses a zero-inflated model.
Taken together these results suggest that both regular and zero-inflated models
can be effective for this type of data, if the parameters are estimated
correctly.

The other three new simulation models (mfa, PhenoPath and SparseDC) do not do a
particularly good job of reproducing this dataset, and in particular mfa
produces a dataset with a very different number of counts per cell. These
simulations have mostly been designed to demonstrate the analysis methods in
these packages and the estimation procedures associated with them are
relatively simple. This result underlines that the key to producing a realistic
simulation of any kind of data lies not so much in the simulation model itself
but in choosing good parameters for that model. As we describe in the
publication, there are caveats around the estimation procedures for some of the
other models, specifically the Lun model, which only estimates the number of
genes and cells, and the scDD model, which is designed for a high-quality
filtered dataset unlike the raw dataset used here. Another important
consideration is that the comparison shown here is based on a single dataset.
As we showed in the publication, different datasets have different biological
and technical features which may be reproduced more accurately by alternative
simulation models.
