## Analysing scRNA-seq data

* Low counts
    * Dropout
    * Bursting
    * Biology
* Ribosomal RNA

Cell capture technologies and scRNA-seq protocols have developed rapidly but
there are still a number of challenges with the data they produce. Existing
approaches are inefficient, capturing around 10 percent of transcripts in a
cell[Grun2014-zn]. When combined with the low sequencing depth per cell this
results in a limited sensitivity and an inability to detect lowly expressed
transcripts. The small amount of starting material also contributes to high
levels of technical noise, complicating downstream analysis and making it
difficult to detect biological differences[Liu2016-wq]. In order to capture
cells they must first be dissociated into single-cell suspensions but this step
can be non-trivial. Some tissues or cell types may be more difficult to
separate than others and the treatments required to break them apart may effect
the health of the cells and their transcriptional profiles. Other cell types
may be too big or have other characteristics that prevent them being captured.
In these cases related techniques that allow the sequencing of RNA from single
nuclei may be more effective. Cells may be damaged during processing, multiple
cells captured together or empty wells or droplets sequenced making quality
control of datasets an important consideration.

As well as increasing technical noise the small amounts of starting material
and low sequencing depth mean there are many occasions where zero counts are
recorded, indicating no measured expression for a particular gene in a
particular cell. These zero counts often represent true biological signal we
are interested as we expect different cell types to express different genes.
However they can also be the result of confounding biological factors such as
stage in the cell cycle, transcriptional bursting and environmental interactions
which cause genuine changes in expression but that might not be of interest to
a particular study. On top of this there are effects that are purely technical
factors in particular sampling effects which mean result in "dropout" events
where a transcript is truly expressed in a sample but is not observed in the
sequencing data. In bulk experiments these effects are limited by averaging
across the cells in a sample but for single-cell experiments they can present
a significant challenge for analysis as methods must account for the missing
information and they may cause the assumptions of existing methods to be
violated. One approach to tackling the problem of too many zeros is to use
zero-inflated versions of common distributions but it is debatable whether
scRNA-seq datasets are truly zero-inflated or the the additional zeros are
better modeled with standard distributions with lower means. Another approach
is to impute some of the zeros, replacing them with estimates of how expressed
those genes truly are based on their expression in similar cells. However
imputation comes with the risk of introducing false structure that is not
really present in the data.

Bulk RNA-seq experiments usually involve predefined groups of samples, for
example cancer cells and normal tissue, different tissue types or treatment and
control groups. It is possible to design scRNA-seq experiments in the same way
for example by sorting cells into known groups based on surface markers,
sampling them at a series of time points or comparing treatment groups but
often they are more exploratory. Many of the single-cell studies to date have
sampled developing or mature tissues and attempted to profile the cell types
that are present[Zeisel2015-rd; Patel2014-bl; Treutlein2014-wd;
Usoskin2015-fz; Buettner2015-rq; Klein2015-iw; Trapnell2014-he]. This
approach is best exemplified by the Human Cell Atlas project which is
attempting to produce a reference of the transcriptional profiles of all the
cell types in the human body. Similar projects exist for other species and
specific tissues. As scRNA-seq datasets have become more widely available a
standard workflow has developed which can be applied to many experiments. This
workflow can be divided into four phases: 1) Data acquisition, Pre-processing
of samples to produce a cell by gene expression matrix, 2) Data cleaning,
quality control to refine the dataset used for analysis, 3) Cell assignment,
grouping or ordering of cells based on their transcriptional profile, and 4)
Gene identification to find genes that represent particular groups and can be
used to interpret them. Within each phase a range processes may be used and
there are now many tools available for completing each of them, with over XXX
tools currently available. An introduction to the phases of scRNA-seq analysis
is provided here but the analysis tools landscape is more fully explored in
Chapter X.

### Pre-processing and quality control

* Alignment
* Droplet selection
* UMIs
* Doublet detection
* Bad cells
* Gene filtering
* Cell ranger
* scater
* cell free DNA

The result of a sequencing experiment is typically a set of image files from
the sequencer or a FASTQ file containing nucleotide reads but for most analyses
we use an expression matrix. To produce this matrix there is a series of
pre-processing steps, typically beginning will some quality control of the raw
reads. Reads are then aligned to a reference genome and the number of reads
overlapping annotated features (genes or transcripts) is counted. In recent
years probabilistic quantification methods such as kallisto[Bray2016-tm] or
Salmon[Patro2015-kl] that estimate transcript expression directly without
requiring complete alignment have become popular as they dramatically reduce
processing time and potentially produce more accurate quantification. These can
be applied to full-length scRNA-seq datasets but have required adaptations such
as the Alevin method for UMI-based datasets. When using conventional alignment
UMI samples need extra processing with tools like UMI-tools[Smith2016-bt] or
umis[Svensson2016-eg] in order to assign cell barcodes and deduplicate UMIs.
For datasets produced using the Chromium platform the Cell Ranger software is
a complete preprocessing pipeline that also includes an automated downstream
analysis. Other packages such as scPipe also aim to streamline this process with
some such as XXX designed to work on scalable cloud based infrastructure which
may be required as bigger datasets continue to be produced.

Quality control of individual cells is important as experiments will contain
low-quality cells that can be uninformative or lead to misleading results.
Quality control can be performed on various levels, from the quality scores of
the reads themselves, how or where reads align to features of the expression
matrix. Particular types of cells that are commonly removed include damaged
cells, doublets where multiple cells have been captured together and empty
droplets or wells that have been sequenced but do not contain a cell. The
Cellity package attempts to automate this process by inspecting a series of
biological and technical features and using machine learning methods to
distinguish between high and low-quality cells[Ilicic2016-wy]. However the
authors found that many of the features were cell type specific and more work
needs to be done to make this approach more generally applicable. The scater
package[McCarthy2016-cw] emphasises a more exploratory approach to quality
control at the expression matrix level but providing a series of functions for
visualising various features of a dataset. These plots can then be used for
selecting thresholds for removing cells. Plate-based capture platforms can
produce additional biases based on the location of individual wells, a problem
which is addressed by the OEFinder package which attempts to identify and
visualise these "ordering effects"[Leng2016-it].

Filtering and selection of features also deserves attention. Genes or
transcripts that are lowly expressed are typically removed from datasets in
order to reduce computational time and multiple-testing correction but it is
unclear how many counts indicate that a gene is truly "expressed". Many
downstream analysis operate on a selected set of genes which can have a
dramatic effect on their results. These features are often selected based on
how variable they are across the dataset but this may be a result of noise
rather than biological importance. Alternative selection methods have been
proposed such as M3Drop which...

### Normalisation and integration

* Why?
* Seurat CCA
* New methods
* Tung?
* Different data types

Technical variation is a known problem in high-throughput genomics studies, for
example it has been estimated that only 17.8 percent of allele-specific
expression is due to biological variation with the rest being technical
noise[Kim2015-mo]. Effective normalisation has been shown to be a crucial
aspect of analysis for bulk RNA-seq datasets and similarly this is true for
single-cell experiments. Some full-length studies use simple transformations
like Reads (or Fragments) Per Kilobase per Million
(RPKM/FPKM)[Mortazavi2008-vu] or Transcripts Per Million (TPM)[Wagner2012-qf]
which correct for the total number of reads per cell and gene length. For UMI
data the gene length correction is not required as reads only come from the
ends of transcripts. Normalisation methods designed for detecting differential
expression between bulk samples such as Trimmed Mean of M-Values
(TMM)[Robinson2010-ll] or the DESeq method[Anders2010-pq] can be applied, but
is is unclear how suitable they are for the single-cell context. Most of the
early normalisation methods developed specifically for scRNA-seq data made use
of spike-ins, synthetic RNA sequences added to cells in known quantities such
as the ERCC.... Brennecke et al.[Brennecke2013-pt], Ding et al.[Ding2015-ht]
and Gr√ºn, Kester and van Oudenaarden[Grun2014-zn] all propose methods for
estimating technical variance using spike-ins, as does Bayesian Analysis of
Single-Cell Sequencing data (BASiCS)[Vallejos2015-ef]. Using spike-ins for
normalisation assumes that they properly capture the dynamics of the underlying
dataset and even if this is the case it is restricted to protocols where they
can be added which does not include droplet-based capture techniques. The scrna
package implements a method that doesn't rely on spike-ins, instead using a
pooling approach to compensate for the large number of zero counts where
expression levels are summed across similar cells before calculating size
factors that are deconvolved back to the original cells[Lun2016-mq]. The
BASiCS method has also been adapted to experiments without spike-ins by..., but
only for designed experiments where groups are known in advance.

Early scRNA-seq studies often made use of only a single sample but as technologies
have become cheaper and more widely available it is common to see studies with
multiple batches or making use of publicly available data produced by other groups.
While this expands the potential insights to be gained it presents a problem as
to how to integrate these datasets and a range of computational approaches for
doing this have been developed. The alignment approach in the Seurat package
uses Canonical Correlation Analysis (CCA) to identify a multi-dimensional
subspace that is consistent between datasets. Dynamic Time Warping (DTW) is then
used to stretch and align these dimensions so that the datasets are similarly
spread along them. Clustering can then be performed using these aligned
dimensions but as the original expression matrix is unchanged the integration
is not used for other tasks such as differential expression testing. The authors
of scran using a Mutual Nearest Neighbours (MNN) approach that... A recent
update to the Seurat method combines these approaches by identifying "anchors"
that...Alternative integration methods such as...

### Grouping cells

* Clustering
* Seurat
* Other approaches
* Comparison
* Classification

Grouping similar cells is a key step in analysing scRNA-seq datasets that is
not usually required for bulk experiment and as such it has been a key focus of
methods development with over XXX tools released for clustering cells. Some of
these methods include SINgle CEll RNA-seq profiling Analysis
(SINCERA)[Guo2015-mf], Single-Cell Consensus Clustering (SC3)[Kiselev2016-fa],
single-cell latent variable model (scLVM)[Buettner2015-rq] and Spanning-tree
Progression Analysis of Density-normalised Events (SPADE)[Anchang2016-vo], as
well as BackSPIN which was used to identify nine cell types and 47 distinct
subclasses in the mouse cortex and hippocampus[Zeisel2015-rd]. All of these
tools attempt to cluster similar cells together based on their expression
profiles, forming groups of cells of the same type. One clustering method that
has become popular is that included in the Seurat package. This method begins
by selecting a set of highly variable genes then performing PCA on them.**NEW
GENE SELECTION** A set of dimensions is then selected that contains most of the
variation in the dataset. Alternatively if Seurat's alignment method has been
used to integrate datasets the aligned CCA dimensions are used instead. Next an
MNN graph is constructed by considering the distance between cells in this
multidimensional space. In order to separate cells into clusters a community
detection algorithm such as Louvain optimisation is run on the graph with a
resolution parameter that controls the number of clusters that are produced.
Seurat's clustering method has been shown too....

For tissue types that are well understood or where comprehensive references are
available an alternative is to directly classify cells. This can be done using
a gating approach based on the expression of known marker genes similar to that
commonly used for flow cytometry experiments. Alternatively machine learning
algorithms can be used to perform classification based on the overall expression
profile. Methods such as ... take this approach. For example... Classification
has the advantage of making use of existing knowledge and avoids manual annotation
and interpretation of clusters which can often be difficult and time consuming.
However it is biased by what is present in the reference datasets used typically
can not reveal previously unknown cell types or states. As projects like the
Human Cell Atlas produce well-annotated references based on scRNA-seq data the
viability of classification and other reference-based methods will improve.

### Ordering cells

* Pseudotime
* Monocle
* Other approaches
* Comparison

In some studies, for example in development where stem cells are
differentiating into mature cell types, it may make sense to order cells along
a continuous trajectory from one cell type to another instead of assigning them
to distinct groups. Trajectory analysis was pioneered by the Monocle package
which used dimensionality reduction and computation of a minimum spanning tree
to explore a model of skeletal muscle differentiation[Trapnell2014-he]. Since
then the Monocle algorithm has been updated and a range of other developed
including TSCAN[Ji2016-ws], SLICER[Welch2016-cw], CellTree[DuVerle2016-ni],
Sincell[Julia2015-zc] and Mpath[Chen2016-kx]. In their comprehensive review and
comparison of trajectory inference methods Cannoodt, Saelens and Saeys break
the process into two steps. In the first step dimensionality reduction
techniques such as PCA or t-SNE[Maaten2008-ne] are used to project cells into
lower**[?]** dimensions where the cells are clustered or a graph constructed
between them. The trajectory is then created by finding a path through the
cells and ordering the cells along it. This review compares the performance on
a range of datasets... They found that...

An alternative continuous approach is the cell velocity method in the velocyto
package. RNA-seq studies typically focus on the expression of complete mature
mRNA molecules but a sample will also contain immature mRNA that are yet to be
spliced. Examining these reads assigned to introns can indicate newly
transcribed mRNA molecules and therefore which genes are currently active.
Instead of assigning cells to discrete groups or along a continuous path
velocyto uses reads from unspliced regions to place them in a space and create
a vector indicating the direction in which the transcriptional profile is
heading. This vector can show the a cell is differentiation in a particular way
or that a specific transcriptional program has been activated.

Deciding on which assignment approach to use depends on the source of the data,
the goals of the study and the questions that are being asked. Both grouping
and ordering can be informative and it is often useful to attempt both on a
dataset and see how they compare.

### Gene detection and interpretation

* DE
* Marker genes
    * Alternatives - Gini, classifiers
* Reviews
* Classification
* Logistic regression

Once cells are assigned by clustering or ordering the problem is to interpret
what these groups represent. For clustered datasets this is usually done by
identifying genes that are differentially expressed across the groups or marker
genes that are expressed in a single cluster. Many methods have been suggested
for testing differential expression some of which take in to account the unique
features of scRNA-seq data. For example...The large number of cells in
scRNA-seq datasets mean that some of the problems that made standard
statistical tests unsuitable for bulk RNA-seq experiments do not apply and
simple methods like the unpaired Wilcoxon rank-sum test (or Mann-Whitney U
test) may give reasonable results in this setting. Methods originally developed
for bulk experiments have have also been applied to scRNA-seq datasets. Some of
these methods have well understood statistical frameworks and have been shown
to perform well in multiple comparisons. However the assumptions they make may
not be appropriate for single-cell data and methods such as ZiNB-WaVe may be
required to transform the data that is appropriate for their use.

Often the goal is not to find all the genes that are differentially expressed
between groups but to identify genes which uniquely mark particular clusters.
This goal is open to alternative approaches such as the Gini coefficient which
measures unequal distribution across a population. Another approach is to
construct machine learning classifiers for each genes to distinguish between
one group and all other cells. Genes that give good classification performance
should be good indicators of what is specific to that cluster.

When cells have been ordered along a continuous trajectory the task is slightly
different. Instead of testing for a difference in means between two groups the
goal is to find genes that have a relationship between expression and
pseudotime. This can be accomplished by fitting splines and testing the
coefficients. For more complex trajectories it can also be useful to find genes
that are differently expressed along each side of a branch points. Monocle's
BEAM method does this by... Genes that are associated with a trajectory are
important in their own right as they describe the biology along a path but they
can also be used to identify cell types at end points.

Interpreting the meaning of detected markers genes is a difficult task as is
likely to remain so. Gene set testing to identify related categories such as
Gene Ontology terms can help but often it is necessary to rely the results of
previous functional studies. This can only be reliably done by working closely
with experts who have significant domain knowledge in the cell types being
studied. An additional concern for unsupervised scRNA-seq studies is that the
same genes are used for clustering or ordering and determining what those
clusters or trajectories mean. This is a problem addressed by XXX who suggest a
differential expression test using a long-tailed distribution for testing genes
following clustering.

### Alternative analyses

* Variant detection
* Cancer
* Immune cells

Some uses of scRNA-seq data fall outside the most common workflow and methods
have been developed for a range of other purposes. For example methods have
been designed for assigning haplotypes to cells, detecting allele-specific
expression, identifying alternative splicing or calling single nucleotide or
complex genomic variants. Other methods have been designed for specific cell
types or tissues such as XXX which can assign immune cell receptors and XXX
which interrogate the development of cancer samples. Most future studies can be
expected to continue to follow common practice but it also expected that
researchers will continue to push the boundaries of what it is possible to
study using scRNA-seq technologies.
